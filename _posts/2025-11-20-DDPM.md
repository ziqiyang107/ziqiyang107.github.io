---
layout: post
title: "DDPM Explained"
date: 2025-11-20
---
## Preliminaries

{% include cite.html key="ho2020denoising"%} proposed a forward/diffusion process, which is a fixed Markov chain, and a reverse process a parameterized Markov chain which is learned to reverse the diffusion process using variational inference. The diffusion process gradually adds (Gaussian) noise to the data in the opposite direction of reverse/sampling process until signal is destroyed, the author also used conditional Gaussian in reverse process transitions, because we can have a relatively simple neural network parameterization. In the following section, we will refer to this paper as DDPM paper. 


Suppose data $\vecx_0 \sim q(\vecx_0)$, where $q(\vecx_0)$ is the true unknown distribution of $\vecx_0$, we use a joint reverse process $p_{\theta}(\vecx_{0:T})$ to model $\vecx_0$ as $p_{\theta}(\vecx_0)=\int p_{\theta}(\vecx_{0:T}) d\vecx_{1:T}$, where $\vecx_1,...,\vecx_T$ are latents of the same dimension $d$ as $\vecx_0$. The reverse process is a learned Markov chain starting at $p(\vecx_T)=N(\vecx_T; \veczero, \vecI)$:

$$
\begin{align*}
p_{\theta}(\vecx_{0:T}) := p(\vecx_T) \prod_{t=1}^T p_{\theta}(\vecx_{t-1}|\vecx_t), \qquad p_{\theta}(\vecx_{t-1}|\vecx_t):=N \big(\vecx_{t-1}; \vecmu_{\theta}(\vecx_t, t), \vecSigma_{\theta}(\vecx_t, t) \big)
\end{align*}
$$

In order to use variational inference, we have approximate posterior called forward/diffusion process

$$
q(\vecx_{1:T}|\vecx_0):=\prod_{t=1}^T q(\vecx_t|\vecx_{t-1})=\prod N(\vecx_t; \sqrt{1-\beta_t}\vecx_{t-1},\beta_t \vecI)
$$

where $\beta_t$'s can be either learned using reparameterization or fixed as hyperparameters, if they are fixed, then there is no learnable parameter in diffusion process $q(\cdot\|\cdot)$. 

## Reverse Process
To explain the motivation of chooseing reverse sampling process as a conditional Gaussian, we first take look at the original paper:
> When the diffusion consists of small amounts of Gaussian noise, it is sufficient to set the sampling chain transitions to conditional Gaussians too, allowing for a particularly simple neural network parameterization.

And
> ...expressiveness of the reverse process is ensured in part by the choice of Gaussian conditionals in $p_{\theta}(x_{t−1}\|x_t)$, because both processes have the same functional form when $$\beta_t$$ are small...

And
> These constants were chosen to be small relative to data scaled to $[−1, 1]$, ensuring that reverse and forward processes have approximately the same functional form while keeping the signal-to-noise ratio at $x_T$ as small as possible ($L_T = D_{KL}(q(x_T \|x_0) \lVert \mathcal{N}(0, \vecI)) ≈ 10^{−5}$ bits per dimension in our experiments)

All these mean if the forward process adds small Gaussian perturbations, then the true reverse conditional $q(x_{t-1}\|x_t)$ should be approximately Gaussian as well, therefore it is appropriate to use a $p_{\theta}(\vecx_{t-1}\|\vecx_t)$ to approximate it. But how do we know the reverse conditional is also Gaussian?

{% capture theorem_content %}
Give the 
$$
\begin{align*}
\text{Forward diffusion }\quad &dX_t = b(X_t, t)dt + \sigma dW_t​  \\
\text{Transition densities }\quad &P(X_t​ \in dy∣X_s​=x) = q_{s,t​}(x,y)dy  \\
\text{Time reversal process }\quad &Y_t :=X_{T−t}​  \\
\end{align*}
$$
we need to show for small time step $dt$, $q(x_{t−h}|x_t)$ is (approximately) Gaussian.
{% endcapture %}

{% capture theorem_proof %}
Based on the forward diffusion, for small $dt$, we can write:
$$
X_t​∣X_{t−h​}=x \sim \mathcal{N}(x+b(x,t−h)h, \sigma^2 h \vecI)+o(h)
$$
then we can write:
$$
q_{t−h,t}​(x,y)=\frac{1}{{(2\pi \sigma^2 h)}^d/2} \​exp{\Big(−\frac{||y−x−b(x,t−h)h||^2}{2\sigma^2 h} \Big)​}+o(h)
$$
{% endcapture %}

{% include theorem.html 
   type="theorem" 
   title="Theorem" 
   name="Reverse conditional approximately Gaussian"
   content=theorem_content 
   proof=theorem_proof 
%}

Using variational inference framework, We can derive the ELBO as follows:
<div id="lower_bound">
$$
\begin{align*}
\log p_{\theta}(\vecx_0) =& \log \int p_{\theta}(\vecx_{0:T}) d\vecx_{1:T}  \\
=& \log \int \frac{p_{\theta}(\vecx_{0:T}) q(\vecx_{1:T}|\vecx_0)}{q(\vecx_{1:T}|\vecx_0)}  d\vecx_{1:T} \\
=& \log E_{q(\vecx_{1:T}|\vecx_0)} \Big[\frac{p_{\theta}(\vecx_{0:T})}{q(\vecx_{1:T}|\vecx_0)} \Big] \\
\geq & E_{q(\vecx_{1:T}|\vecx_0)} \Big[\log \frac{p_{\theta}(\vecx_{0:T})}{q(\vecx_{1:T}|\vecx_0)} \Big]    \\
=& E_{q(\vecx_{1:T}|\vecx_0)} \Big[\log \frac{p(\vecx_T) \prod_{t=1}^T p_{\theta}(\vecx_{t-1}|\vecx_t)}{\prod_{t=1}^T q(\vecx_t|\vecx_{t-1})} \Big]  \\
=& E_{q(\vecx_{1:T}|\vecx_0)} \Big[\log \frac{p(\vecx_T)p_{\theta}(\vecx_0|\vecx_1) \prod_{t=2}^T p_{\theta}(\vecx_{t-1}|\vecx_t)}{q(\vecx_1|\vecx_0)\prod_{t=2}^T q(\vecx_t|\vecx_{t-1},\vecx_0)} \Big] \quad \text{by Markov property of $q$} \\
=& E_{q(\vecx_{1:T}|\vecx_0)} \Big[\log \frac{p(\vecx_T)p_{\theta}(\vecx_0|\vecx_1)}{q(\vecx_1|\vecx_0)} + \log\prod_{t=2}^T \frac{p_{\theta}(\vecx_{t-1}|\vecx_t)}{\frac{q(\vecx_{t-1}|\vecx_t, \vecx_0)q(\vecx_t|\vecx_0)}{q(\vecx_{t-1}|\vecx_0)}} \Big] \quad \text{by Bayes rule}  \\
=& E_{q(\vecx_{1:T}|\vecx_0)} \Big[\log \frac{p(\vecx_T)p_{\theta}(\vecx_0|\vecx_1)}{q(\vecx_1|\vecx_0)} + \log \frac{q(\vecx_1|\vecx_0)}{q(\vecx_T|\vecx_0)} + \log \prod_{t=2}^T \frac{p_{\theta}(\vecx_{t-1}|\vecx_t)}{q(\vecx_{t-1}|\vecx_t, \vecx_0)}\Big]   \\
=& E_{q(\vecx_{1:T}|\vecx_0)} \Big[\log \frac{p(\vecx_T)p_{\theta}(\vecx_0|\vecx_1)}{q(\vecx_T|\vecx_0)} + \sum_{t=2}^T \log \frac{p_{\theta}(\vecx_{t-1}|\vecx_t)}{q(\vecx_{t-1}|\vecx_t, \vecx_0)} \Big] \\
=& E_{q(\vecx_1|\vecx_0)} [\log p_{\theta}(\vecx_0|\vecx_1)] + E_{q(\vecx_T|\vecx_0)} \Big[\log \frac{p(\vecx_T)}{q(\vecx_T|\vecx_0)} \Big] + \sum_{t=2}^T E_{q(\vecx_t, \vecx_{t-1}|\vecx_0)}\Big[\frac{p_{\theta}(\vecx_{t-1}|\vecx_t)}{q(\vecx_{t-1}|\vecx_t, \vecx_0)} \Big]
 \\
=& E_{q(\vecx_1|\vecx_0)} [\log p_{\theta}(\vecx_0|\vecx_1)] - D_{KL}(q(\vecx_T|\vecx_0)||p(\vecx_T)) -  \\
& \sum_{t=2}^T E_{q(\vecx_t|\vecx_0)} [D_{KL}(q(\vecx_{t-1}|\vecx_t, \vecx_0)||p_{\theta}(\vecx_{t-1}|\vecx_t))]  \tag{lower bound}
\end{align*}
$$
</div>

This equation is almost the equation(5) in {% include cite.html key="ho2020denoising"%}, but doesn't include the expectation over $\vecx_0$ and sign is reversed. We use the same definition as in the DDPM paper

$$
\begin{align*}
L_0 &:= -\log p_{\theta}(\vecx_0|\vecx_1) \\
L_{t-1} &:=  D_{KL}(q(\vecx_{t-1}|\vecx_t, \vecx_0)||p_{\theta}(\vecx_{t-1}|\vecx_t)) \\
L_T &:= D_{KL}(q(\vecx_T|\vecx_0)||p(\vecx_T))
\end{align*}
$$

So we have 

Equation [(lower bound)](#lower_bound)$$= -E_{\vecx_1 \sim q(\vecx_1\|\vecx_0)}[L_0] - L_T - \sum_{t=2}^T E_{\vecx_t \sim q(\vecx_t\|\vecx_0)}[L_{t-1}]$$

Maximizing this ELBO corresponds to minimizing the following (ignore $L_T$ since it has no trainable parameter, where we also include the expectation of $\vecx_0$):
\begin{align}
E_{\vecx_0 \sim q(\vecx_0)} \underset{term~1}{\boxed{E_{\vecx_1 \sim q(\vecx_1|\vecx_0)}[L_0]}} + \sum_{t>1} E_{\vecx_0 \sim q(\vecx_0)} \underset{term~2}{\boxed{E_{\vecx_t \sim q(\vecx_t|\vecx_0)} [L_{t-1}]}} \label{Eq: raw upper bound}
\end{align}
Later, authors simplify this into a simplified version, and we will see how to derive that.

<span style="color:red">Derive $q(\vecx_t\|\vecx_0)$:</span>


In order to derive equation (6)(7) in {% include cite.html key="ho2020denoising"%}, we first need to find $q(\vecx_t\|\vecx_0)$. Using reparameterization trick, we can write $\vecx_t = \sqrt{\alpha_t}\vecx_{t-1}+\sqrt{1-\alpha_t}\veceps_{t-1}$, where $\veceps_{t-1} \sim N(0, \vecI)$, $\alpha_t:=1-\beta_t$. Similarly we expand $\vecx_{t-1}$ and get:

$$
\begin{align*}
\vecx_t =& \sqrt{\alpha_t}\vecx_{t-1}+\sqrt{1-\alpha_t}\veceps_{t-1} \\
=& \sqrt{\alpha_t} \Big(\sqrt{\alpha_{t-1}}\vecx_{t-2}+\sqrt{1-\alpha_{t-1}}\veceps_{t-2} \Big) + \sqrt{1-\alpha_t}\veceps_{t-1}  \\
=& \sqrt{\alpha_t \alpha_{t-1}}\vecx_{t-2} + \sqrt{\alpha_t(1-\alpha_{t-1})}\veceps_{t-2} + \sqrt{1-\alpha_t}\veceps_{t-1} \\
=& \sqrt{\alpha_t \alpha_{t-1}}\vecx_{t-2} + \sqrt{1-\alpha_t\alpha_{t-1}} \veceps_{t-2}^* \quad \text{$\veceps_{t-2}^*$ is another standard normal random variable}  \\
=& ... = \sqrt{\bar{\alpha}_t} \vecx_0 + \sqrt{1-\bar{\alpha}_t} \veceps_0 \quad \text{where authors define $\bar{\alpha}_t=\prod_{s=1}^t \alpha_s$}\\
\sim& N(\sqrt{\bar{\alpha}_t} \vecx_0, (1-\bar{\alpha}_t)\vecI)
\end{align*}
$$

<span style="color:red">Derive equation(6)(7) in </span>{% include cite.html key="ho2020denoising"%}:

$$
\begin{align*}
q(\vecx_{t-1}|\vecx_t, \vecx_0) \propto & q(\vecx_t|\vecx_{t-1}, \vecx_0) q(\vecx_{t-1}|\vecx_0) \\
=& N(\vecx_t;\sqrt{\alpha_t}\vecx_{t-1}, (1-\alpha_t)\vecI)N(\vecx_{t-1};\sqrt{\bar{\alpha}_{t-1}}\vecx_0, (1-\bar{\alpha}_{t-1})\vecI)
\end{align*}
$$

We observe this is the quadratic form of $\vecx_{t-1}$ inside a exponential function, so $\vecx_{t-1}$ is normally distributed. By completing the square approach, we have $q(\vecx_{t-1}\|\vecx_t, \vecx_0) = N(\vecx_{t-1};\tilde{\vecmu}_t(\vecx_t, \vecx_0), \tilde{\beta}_t \vecI)$, where

$$
\tilde{\vecmu}_t(\vecx_t, \vecx_0) := \frac{\sqrt{\bar{\alpha}_{t-1}}\beta_t}{1-\bar{\alpha}_t}\vecx_0 + \frac{\sqrt{\alpha_t}(1-\bar{\alpha}_{t-1})}{1-\bar{\alpha}_t}\vecx_t, \quad \tilde{\beta}_t:=\frac{1-\bar{\alpha}_{t-1}}{1-\bar{\alpha}_{t-1}}\beta_t
$$

<span style="color:red">Four equivalent approaches in simplifying $L_{t-1}$:</span>

Recall 

$$
\begin{align*}
L_{t-1}&=D_{KL}(q(\vecx_{t-1}|\vecx_t, \vecx_0)||p_{\theta}(\vecx_{t-1}|\vecx_t)) \\
q(\vecx_{t-1}|\vecx_t, \vecx_0) &= N(\vecx_{t-1};\tilde{\vecmu}_t(\vecx_t, \vecx_0), \tilde{\beta}_t \vecI) \\
p_{\theta}(\vecx_{t-1}|\vecx_t)&=N \big(\vecx_{t-1}; \vecmu_{\theta}(\vecx_t, t), \vecSigma_{\theta}(\vecx_t, t) \big)
\end{align*}
$$

$$\textbf{Approach 1:}$$  \\
We simplify:

$$
\begin{align}
L_{t-1} =& D_{KL}(q(\vecx_{t-1}|\vecx_t, \vecx_0)||p_{\theta}(\vecx_{t-1}|\vecx_t))  \\
=& D_{KL} \Big(N(\vecx_{t-1};\tilde{\vecmu}_t(\vecx_t, \vecx_0), \tilde{\beta}_t \vecI)~||~ N \big(\vecx_{t-1}; \vecmu_{\theta}(\vecx_t, t), \vecSigma_{\theta}(\vecx_t, t) \big)  \Big) \\
=& \frac{1}{2}\Big[\log \frac{|\vecSigma_{\theta}|}{|\tilde{\beta}_t\vecI|} - d + tr(\vecSigma_{\theta}^{-1}(\tilde{\beta}_t\vecI))+(\tilde{\vecmu}_t - \vecmu_{\theta})^T \vecSigma_{\theta}^{-1}(\tilde{\vecmu}_t - \vecmu_{\theta})\Big] \\
&\text{In order to minimize two normal distributions as closely as possible,} \\
&\text{we don't need to model $\vecSigma_{\theta}$ individually, but set it to be a constant(assume fixed $\alpha_t$),} \\
&\text{and equal to $\tilde{\beta}_t\vecI$, then we have:} \\
=& \frac{1}{2\tilde{\beta}_t} ||\tilde{\vecmu}_t(\vecx_t, \vecx_0) - \vecmu_{\theta}(\vecx_t, t)||^2 + C  \label{Eq: L_t-1}
\end{align}
$$

We can parametrize $\vecmu_{\theta}(\vecx_t, t)$ by a neural network and train it to predict $\tilde{\vecmu}_t$, but authors in DDPM say this will lead to worse sample quality early in their experiments

$$\textbf{Approach 2 & 3}$$  \\
Since we know 

$$
\begin{align}
\tilde{\vecmu}_t(\vecx_t, \vecx_0) =& \frac{\sqrt{\bar{\alpha}_{t-1}}\beta_t}{1-\bar{\alpha}_t}\vecx_0 + \frac{\sqrt{\alpha_t}(1-\bar{\alpha}_{t-1})}{1-\bar{\alpha}_t}\vecx_t  \label{Eq:mu_t form x} \\
=& \frac{\sqrt{\alpha_t}(1-\bar{\alpha}_{t-1})}{1-\bar{\alpha}_t}\vecx_t + \frac{\sqrt{\bar{\alpha}_{t-1}}(1-\alpha_t)}{1-\bar{\alpha}_t} \frac{\vecx_t - \sqrt{1-\bar{\alpha}_t}\veceps_t}{\sqrt{\bar{\alpha}_t}}  \\
=& \frac{\sqrt{\alpha}_t(1-\bar{\alpha}_{t-1})+\frac{1-\alpha_t}{\sqrt{\alpha_t}}}{1-\bar{\alpha}_t}\vecx_t - \frac{1-\alpha_t}{\sqrt{\alpha_t}}\frac{1}{\sqrt{1-\bar{\alpha}_t}}\veceps_t \\
=& \frac{\alpha_t(1-\bar{\alpha}_{t-1})+1-\alpha_t}{\sqrt{\alpha_t}(1-\bar{\alpha}_t)}\vecx_t - \frac{1-\alpha_t}{\sqrt{\alpha_t}}\frac{1}{\sqrt{1-\bar{\alpha}_t}}\veceps_t  \\
=& \frac{1}{\sqrt{\alpha_t}}\Big(\vecx_t - \frac{1-\alpha_t}{\sqrt{1-\bar{\alpha}_t}}\veceps_t \Big) \label{Eq: mu_t form eps}
\end{align}
$$

where we use $q(\vecx_t\|\vecx_0)=N(\sqrt{\bar{\alpha}_t} \vecx_0, (1-\bar{\alpha}_t)\vecI)$ in reparametrization relation $\vecx_t = \sqrt{\bar{\alpha}_t} \vecx_0 +  \sqrt{1-\bar{\alpha}_t} \veceps_t$, where $\veceps_t \sim N(\veczero, \vecI)$, to get $\vecx_0 = \frac{\vecx_t - \sqrt{1-\bar{\alpha}_t}\veceps_t}{\sqrt{\bar{\alpha}_t}}$

In order to match $\vecmu_{\theta}(\vecx_t, t)$ to $\tilde{\vecmu}_t$ as closely as possible, we set it to form:

$$
\begin{align}
\vecmu_{\theta}(\vecx_t, t) =& \frac{\sqrt{\bar{\alpha}_{t-1}}\beta_t}{1-\bar{\alpha}_t}\vecx_{\theta}(\vecx_t, t) + \frac{\sqrt{\alpha_t}(1-\bar{\alpha}_{t-1})}{1-\bar{\alpha}_t}\vecx_t  \label{Eq: mu_theta form x}  \\
=& \frac{1}{\sqrt{\alpha_t}}\Big(\vecx_t - \frac{1-\alpha_t}{\sqrt{1-\bar{\alpha}_t}}\veceps_{\theta}(\vecx_t, t) \Big)  \label{Eq: mu_theta form eps}
\end{align}
$$

where we let $$\vecx_{\theta}(\vecx_t, t)=\frac{\vecx_t - \sqrt{1-\bar{\alpha}_t}\veceps_{\theta}(\vecx_t, t)}{\sqrt{\bar{\alpha}_t}}$$ to match the form of $\vecx_0$, this has similar derivation as above $$\tilde{\vecmu}_t(\vecx_t, \vecx_0)$$. We can parametrize $$\vecx_{\theta}(\vecx_t, t)$$ or $$\veceps_{\theta}(\vecx_t, t)$$ with neural network, as $$\vecmu_\theta$$ in approach 1.

We plug in different forms of $\vecmu_\theta$ and $\tilde{\vecmu}_t$, we will get different result.

$$
\begin{align*}
&\text{If we plug formula \eqref{Eq:mu_t form x} and \eqref{Eq: mu_theta form x} into \eqref{Eq: L_t-1}, we get:} \\
L_{t-1} &=
\frac{1}{2\tilde{\beta}_t} ||\tilde{\vecmu}_t(\vecx_t, \vecx_0) - \vecmu_{\theta}(\vecx_t, t)||^2 + C \\
&= \frac{1}{2\tilde{\beta}_t}\frac{\bar{\alpha}_{t-1}(1-\alpha_t)^2}{(1-\bar{\alpha}_t)^2} ||\vecx_0 - \vecx_{\theta}(\vecx_t, t)||^2 \qquad \text{(approach 2)} \\
&\text{If we plug formula \eqref{Eq: mu_t form eps} and \eqref{Eq: mu_theta form eps} into \eqref{Eq: L_t-1}, we get:} \\
L_{t-1} &= \frac{1}{2\tilde{\beta}_t} \frac{(1-\alpha_t)^2}{(1-\bar{\alpha}_t)\alpha_t}||\veceps_t - \veceps_{\theta}(\vecx_t, t)||^2 \qquad \text{(approach 3)} \\
&= \frac{1}{2\tilde{\beta}_t} \frac{(1-\alpha_t)^2}{(1-\bar{\alpha}_t)\alpha_t}||\veceps_t - \veceps_{\theta}(\sqrt{\bar{\alpha}_t}\vecx_0+\sqrt{1-\bar{\alpha}_t}\veceps_t, t)||^2 \\ 
&\text{This is almost the formula(12) in DDPM paper}
\end{align*}
$$

$\textbf{Approach 4:}$  

<span style="color:red">Derive equation(14) in DDPM paper:</span>

Following the notation in DDPM paper, $p_{\theta}(\vecx_0\|\vecx_1)=N(\vecx_0;\vecmu_{\theta}(\vecx_1, 1), \sigma_1^2 \vecI)$, where $\sigma_1^2 = \tilde{\beta}_t$

We first derive term 1 in \eqref{Eq: raw upper bound}:

$$
\begin{align}
term~1 =& -E_{\vecx_1 \sim q(\vecx_1|\vecx_0)}\log p_{\theta}(\vecx_0|\vecx_1) \\
=& -E_{\vecx_1 \sim q(\vecx_1|\vecx_0)} \log \prod_{i=1}^D \Big(\frac{2}{255}\frac{1}{\sqrt{2\pi \sigma_1^2}}e^{-\frac{[\vecx_0^i - \mu_{\theta}^i(\vecx_1, 1)]^2}{2\sigma_1^2}} \Big) \\
=& C - \sum_{i=1}^D E_{\vecx_1 \sim q(\vecx_1|\vecx_0)}\frac{-\Big[\vecx_0^i - \frac{1}{\sqrt{\alpha_1}}(\vecx_1^i - \frac{\beta_1}{\sqrt{1-\alpha_1}}\epsilon_{\theta}^i(\vecx_1, 1))\Big]^2}{2\sigma_1^2} \qquad \text{by \eqref{Eq: mu_theta form eps}} \\
=& C + \sum_{i=1}^D E_{\veceps_1 \sim N(\veczero, \vecI)}\frac{\Big[\vecx_0^i-(\vecx_0^i+\frac{\sqrt{1-\alpha_1}}{\sqrt{\alpha_1}}\veceps_1^i)+\frac{\sqrt{1-\alpha_1}}{\sqrt{\alpha_1}}\veceps_{\theta}(\sqrt{\alpha_1}\vecx_0 + \sqrt{1-\alpha_1}\veceps_1,1)^i \Big]^2}{2\sigma_1^2} \qquad \\
&\text{based on reparametrization formula $\vecx_1 = \sqrt{\alpha_1}\vecx_0 + \sqrt{1-\alpha_1}\veceps_1$}  \\
=& C + \sum_{i=1}^D E_{\veceps_1 \sim N(\veczero, \vecI)} \frac{\frac{1-\alpha_1}{\alpha_1}[\veceps_1^i-\veceps_{\theta}^{i}(\sqrt{\alpha_1}\vecx_0 + \sqrt{1-\alpha_1}\veceps_1, 1)]^2}{2\sigma_1^2} \\
=& C + E_{\veceps_1 \sim N(\veczero, \vecI)}\Big[ \frac{(1-\alpha_1)}{2\sigma_1^2 \alpha_1}||\veceps_1 - \veceps_{\theta}(\sqrt{\alpha_1}\vecx_0 + \sqrt{1-\alpha_1}\veceps_1, 1)||^2 \Big] \\
=& C + E_{\veceps_1 \sim N(\veczero, \vecI)}\Big[ \frac{(1-\alpha_1)^2}{2\tilde{\beta}_1(1-\bar{\alpha}_1) \alpha_1}||\veceps_1 - \veceps_{\theta}(\sqrt{\alpha_1}\vecx_0 + \sqrt{1-\alpha_1}\veceps_1, 1)||^2 \Big]
\end{align}
$$

where $\vecx_0^i, \vecx_1^i$ are the $i$th dimension of $\vecx_0$ and $\vecx_1$.

Then we derive term 2 in \eqref{Eq: raw upper bound}:

$$
\begin{align*}
term~2 =& E_{\vecx_t \sim q(\vecx_t|\vecx_0)}[L_{t-1}]\\
=& E_{\vecx_t \sim q(\vecx_t|\vecx_0)}\Big[\frac{1}{2\tilde{\beta}_t} \frac{(1-\alpha_t)^2}{(1-\bar{\alpha}_t)\alpha_t}||\veceps_t - \veceps_{\theta}(\vecx_t, t)||^2 \Big] \qquad \text{plug in (approach 3) formula} \\
=& E_{\veceps_t \sim N(\veczero, \vecI)}\Big[\frac{1}{2\tilde{\beta}_t} \frac{(1-\alpha_t)^2}{(1-\bar{\alpha}_t)\alpha_t}||\veceps_t - \veceps_{\theta}(\sqrt{\bar{\alpha}_t}\vecx_0+\sqrt{1-\bar{\alpha}_t} \veceps_t, t)||^2 \Big]
\end{align*}
$$

Now we have the formula for term 1 and term 2, we can plug them into \eqref{Eq: raw upper bound}, and get:

$$
\begin{align*}
\sum_{t=1}^T E_{\vecx_0, \veceps_t \sim N(\veczero, \vecI)} \Big[\frac{1}{2\tilde{\beta}_t} \frac{(1-\alpha_t)^2}{(1-\bar{\alpha}_t)\alpha_t}||\veceps_t - \veceps_{\theta}(\sqrt{\bar{\alpha}_t}\vecx_0+\sqrt{1-\bar{\alpha}_t} \veceps_t, t)||^2 \Big]
\end{align*}
$$

The authors of DDPM paper decide to drop the constant before the norm, and also sample $t$ uniformly between $\{1,2,...,T\}$, and they get a simplified form the loss to minimize:

$$
\begin{align*}
L_{simple}(\theta):=E_{t, \vecx_0, \veceps_t}\Big[||\veceps_t - \veceps_{\theta}(\sqrt{\bar{\alpha}_t}\vecx_0+\sqrt{1-\bar{\alpha}_t} \veceps_t, t)||^2 \Big]
\end{align*}
$$

## Training and Inference
During training, we first sample $\vecx_0$ from training data, and $t \sim U[0,1]$, take the gradient of above $L_2$ loss, until converged. For sampling, first generate $\vecx_T \sim \mathcal{N}(\veczero, \vecI)$, and from $T \rightarrow 1$, recursively sample from $p_{theta}(\vecx_{t-1}\|\vecx_t)=\mathcal{N} \big(\vecx_{t-1}; \vecmu_{\theta}(\vecx_t, t), \vecSigma_{\theta}(\vecx_t, t) \big)$, which we have the explicity form:

$$
\vecx_{t-1}= \frac{1}{\sqrt{\alpha_t}}\Big(\vecx_t - \frac{1-\alpha_t}{\sqrt{1-\bar{\alpha}_t}}\veceps_{\theta}(\vecx_t, t) \Big) + \sigma_t \vecz \quad \text{where }\vecz \sim \mathcal{N}(\veczero, \vecI)
$$

$\vecx_0$ is our generated sample



---
{% include bibliography.html keys="ho2020denoising,lipman2022flow" %}
